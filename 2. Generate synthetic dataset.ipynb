{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import *\n",
    "import math\n",
    "\n",
    "import Augmentor\n",
    "import random\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "define the object directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_dir = \"objects\"\n",
    "\n",
    "# names of the folders in objects/\n",
    "categories = ['one_way_sign_left', 'one_way_sign_right', 'road_closed_sign', 'stop_sign', 'traffic_drum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth edges on template images\n",
    "# def smooth_borders(im):\n",
    "#     h, w = im.shape[:2]\n",
    "#     amt = 3\n",
    "#     top_bot = np.zeros((3, w, 4))\n",
    "#     top_bot[:] = (0, 0, 0, 0)\n",
    "#     left_right = np.zeros((h+2*amt, 3, 4))\n",
    "#     left_right[:] = (0, 0, 0, 0)\n",
    "\n",
    "#     im = np.concatenate((top_bot, im, top_bot), axis=0)\n",
    "#     im = np.concatenate((left_right, im, left_right), axis=1)\n",
    "\n",
    "#     b, g, r, a = cv2.split(im)\n",
    "#     a = cv2.GaussianBlur(a, (5,5), 5)\n",
    "#     smoothened = cv2.merge((b, g, r, a))\n",
    "\n",
    "#     return smoothened\n",
    "\n",
    "# for cat in categories:\n",
    "#     if not os.path.isdir(os.path.join(\"smooth\", cat)):\n",
    "#         os.mkdir(os.path.join(\"smooth\", cat))\n",
    "#     cat_path = os.path.join(object_dir, cat)\n",
    "#     objs = os.listdir(cat_path)\n",
    "#     for i, obj in enumerate(objs):\n",
    "#         obj_path = os.path.join(cat_path, obj)\n",
    "#         im = cv2.imread(obj_path, cv2.IMREAD_UNCHANGED)\n",
    "#         smooth = smooth_borders(im)\n",
    "#         cv2.imwrite(os.path.join(\"smooth\", cat, \"%s-%d.png\" % (cat, i)), smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "Next, we will perform a random perspective transform as well as motion blur on each image and generate 50 samples per template image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now playing: one_way_sign_left\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'objects/one_way_sign_left'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-96c0ec568696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Iterate through images in classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcurr_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcat_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mim_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_objs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'objects/one_way_sign_left'"
     ]
    }
   ],
   "source": [
    "# Iterate through object classes\n",
    "if not os.path.isdir(\"temp\"):\n",
    "    os.mkdir(\"temp\")\n",
    "for cat in categories:\n",
    "    print(\"Now playing:\", cat)\n",
    "    if not os.path.isdir(os.path.join(\"temp\", cat)):\n",
    "        os.mkdir(os.path.join(\"temp\", cat))\n",
    "    # Iterate through images in classes\n",
    "    curr_dir = os.path.join(object_dir, cat)\n",
    "    cat_objs = os.listdir(curr_dir)\n",
    "    im_idx=1\n",
    "    for obj in cat_objs:\n",
    "        obj_path = os.path.join(curr_dir, obj)\n",
    "        # Generate 50 samples from each class\n",
    "        for _ in range(50):\n",
    "            # Read image\n",
    "            im = cv2.imread(obj_path, cv2.IMREAD_UNCHANGED)\n",
    "            \n",
    "            # Perspective transform\n",
    "            if random.random() < 0.8:\n",
    "                im = perspective_transform(im)\n",
    "            \n",
    "            # Motion blur\n",
    "            if random.random() < 0.8:\n",
    "                im = motion_blur(im, size=random.randint(3, 15))\n",
    "            aug_path = \"temp/%s/%s-%d.png\" % (cat, cat, im_idx)\n",
    "            cv2.imwrite(aug_path, im)\n",
    "            im_idx += 1\n",
    "print(\"done!\")\n",
    "#             # JPEG Compression (to generate artifacts)\n",
    "#             im = compress_jpeg(im, min_quality=i*5, max_quality=i*5+5)\n",
    "\n",
    "            # Salt and pepper noise. Some papers claim it helps, some claim it hurts. who really knows?\n",
    "#             if(random.random() < 0.3):\n",
    "#                 im = noisy(im, \"s&p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=606x212 at 0x7F8F483C0CC0>:   0%|          | 2/2000 [00:00<05:31,  6.03 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to temp/one_way_sign_left/../../output/one_way_sign_left."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=624x275 at 0x7F8F4817AAC8>: 100%|██████████| 2000/2000 [00:12<00:00, 155.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/2000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 250 image(s) found.\n",
      "Output directory set to temp/one_way_sign_right/../../output/one_way_sign_right."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=510x211 at 0x7F8F48204A58>: 100%|██████████| 2000/2000 [00:11<00:00, 174.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGBA size=287x192 at 0x7F8F4840FE10>:   0%|          | 1/2000 [00:00<05:38,  5.90 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 400 image(s) found.\n",
      "Output directory set to temp/road_closed_sign/../../output/road_closed_sign."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=646x451 at 0x7F8F481BE5C0>: 100%|██████████| 2000/2000 [00:15<00:00, 275.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGBA size=258x256 at 0x7F8F4832D6D8>:   0%|          | 0/2000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 350 image(s) found.\n",
      "Output directory set to temp/stop_sign/../../output/stop_sign."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=235x229 at 0x7F8F481BA978>: 100%|██████████| 2000/2000 [00:20<00:00, 95.69 Samples/s] \n",
      "Executing Pipeline:   0%|          | 0/2000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to temp/traffic_drum/../../output/traffic_drum."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=163x299 at 0x7F8F481959E8>: 100%|██████████| 2000/2000 [00:14<00:00, 142.05 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"output\"):\n",
    "    os.mkdir(\"output\")\n",
    "for cat in categories:\n",
    "    p = Augmentor.Pipeline(\"temp/\"+cat, output_directory=\"../../output/\"+cat)\n",
    "\n",
    "    # Slightly distort picture. It should add a little variance to the objects\n",
    "    p.random_distortion(probability=0.5, grid_width=4, grid_height=4, magnitude=1)\n",
    "\n",
    "    # Change brightness, color, contrast\n",
    "    p.random_brightness(0.8, 0.6, 1)\n",
    "    p.random_color(0.8, 0.6, 1)\n",
    "    p.random_contrast(0.8, 0.5, 1)\n",
    "\n",
    "    # Replace random section with noise\n",
    "    p.random_erasing(probability=0.05, rectangle_area=0.65)\n",
    "    p.random_erasing(probability=0.1,  rectangle_area=0.55)\n",
    "    p.random_erasing(probability=0.3,  rectangle_area=0.35)\n",
    "    p.random_erasing(probability=0.3,  rectangle_area=0.25)\n",
    "    p.random_erasing(probability=0.3,  rectangle_area=0.15)\n",
    "\n",
    "    # 2D rotation\n",
    "    p.rotate_without_crop(probability=0.9, max_left_rotation=5, max_right_rotation=5, expand=True)\n",
    "    p.rotate_without_crop(probability=0.2, max_left_rotation=5, max_right_rotation=5, expand=True)\n",
    "\n",
    "    # Create 2000 new thumbnails for every class\n",
    "    p.sample(2000)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we paste the augmented objects onto background images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths of all backgrounds\n",
    "background_paths = [os.path.join(\"backgrounds\", bg_path) for bg_path in os.listdir(\"backgrounds\")]\n",
    "random.shuffle(background_paths)\n",
    "\n",
    "cat_paths = [os.path.join(\"output\", cat) for cat in categories]\n",
    "\n",
    "# Get paths of all generated objects\n",
    "obj_paths = []\n",
    "for cat in categories:\n",
    "    cat_path = os.path.join(\"output\", cat)\n",
    "    for obj_path in os.listdir(cat_path):\n",
    "        obj_paths.append({\n",
    "            \"category\": cat,\n",
    "            \"path\": os.path.join(cat_path, obj_path)\n",
    "        })\n",
    "\n",
    "# Shuffle object paths\n",
    "random.shuffle(obj_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20833  images left\n",
      "20333  images left\n",
      "19833  images left\n",
      "19333  images left\n",
      "18833  images left\n",
      "18333  images left\n",
      "17833  images left\n",
      "17333  images left\n",
      "16833  images left\n",
      "16333  images left\n",
      "15833  images left\n",
      "15333  images left\n",
      "14833  images left\n",
      "14333  images left\n",
      "13833  images left\n",
      "13333  images left\n",
      "12833  images left\n",
      "12333  images left\n",
      "11833  images left\n",
      "11333  images left\n",
      "10833  images left\n",
      "Copying over the remaining 10832 images...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "curr_obj_idx = 0\n",
    "\n",
    "for bg_idx, bg_path in enumerate(background_paths):\n",
    "    if bg_idx % 500 == 0:\n",
    "        print(len(background_paths) - bg_idx, \" images left\")\n",
    "        \n",
    "    # Check if we've gone through all the objects\n",
    "    if bg_idx > 10000:\n",
    "        remaining_bgs = background_paths[bg_idx:]\n",
    "        print(\"Copying over the remaining\", len(remaining_bgs), \"images...\")\n",
    "        for rem_idx, rem_bg_path in enumerate(remaining_bgs):\n",
    "            new_bg_path = \"generated/rem-%d.jpg\" % rem_idx\n",
    "            bbox_path = \"generated/rem-%d.txt\" % rem_idx\n",
    "            \n",
    "            # Copy image to generated folder\n",
    "            copyfile(rem_bg_path, new_bg_path)\n",
    "            \n",
    "            # Create empty annotation file\n",
    "            open(bbox_path, 'w').close()\n",
    "        break\n",
    "        \n",
    "    background = cv2.imread(bg_path)\n",
    "    bg_h, bg_w = background.shape[:2]\n",
    "    \n",
    "    # Generate new path names\n",
    "    new_bg_path = \"generated/img-%d.jpg\" % bg_idx\n",
    "    bbox_path = \"generated/img-%d.txt\" % bg_idx\n",
    "    \n",
    "    # Open bounding box file\n",
    "    bbox_file = open(bbox_path, 'w')\n",
    "    \n",
    "    # Place between 1 and 5 objects on each image\n",
    "    num_objs = random.randint(1, 5)\n",
    "    ignore_bboxes = []\n",
    "    for _ in range(num_objs):\n",
    "        # If we've gone through all our objects, shuffle and go again\n",
    "        if curr_obj_idx >= len(obj_paths):\n",
    "            random.shuffle(obj_paths)\n",
    "            curr_obj_idx = 0\n",
    "        obj_cat = obj_paths[curr_obj_idx][\"category\"]\n",
    "        obj_path = obj_paths[curr_obj_idx][\"path\"]\n",
    "        \n",
    "        obj = cv2.imread(obj_path, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        background, bbox = paste_random(background, obj, ignore_bboxes)\n",
    "        ignore_bboxes.append(bbox)\n",
    "        \n",
    "        x1, y1 = bbox[0]\n",
    "        x2, y2 = bbox[1]\n",
    "        \n",
    "        bbox_file.write(\"%d %d %d %d %d %d %s\\n\" % (x1, y1, x2, y2, bg_w, bg_h, obj_cat))\n",
    "        curr_obj_idx += 1\n",
    "    bbox_file.close()\n",
    "    cv2.imwrite(new_bg_path, background)\n",
    "print(\"done!\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temp = 0\n",
    "bg_idx = 0\n",
    "for cat in categories:\n",
    "    cat_out_path = os.path.join(\"generated\", cat)\n",
    "    if not os.path.exists(cat_out_path):\n",
    "        os.mkdir(cat_out_path)\n",
    "    cat_path = os.path.join(\"output\", cat)\n",
    "    cat_objs = [os.path.join(cat_path, obj_path) for obj_path in os.listdir(cat_path)]\n",
    "    for obj_idx, obj_path in enumerate(cat_objs):\n",
    "        break\n",
    "        obj = cv2.imread(obj_path, cv2.IMREAD_UNCHANGED)\n",
    "        background = cv2.imread(os.path.join(\"backgrounds\", backgrounds[bg_idx]))\n",
    "        bg_idx += 1\n",
    "        \n",
    "        num_objects = random.randint(1, 4)\n",
    "        ignore_bboxes = []\n",
    "        for _ in range(num_objects):\n",
    "            background, bbox = paste_random(background, obj, ignore_bboxes)\n",
    "            ignore_bboxes.append(bbox)\n",
    "        \n",
    "        # Save augmented image\n",
    "        res_path = os.path.join(cat_out_path, \"%s-%d.jpg\" % (cat, obj_idx))\n",
    "        cv2.imwrite(res_path, background)\n",
    "        \n",
    "        # Save bounding boxes\n",
    "#         bbox_path = os.path.join(cat_out_path, \"%s-%d.txt\" % (cat, obj_idx))\n",
    "#         with open(bbox_path, 'w') as f:\n",
    "#             f.\n",
    "#         break\n",
    "        if temp > 10:\n",
    "            break\n",
    "        temp += 1\n",
    "    break\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
