{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import *\n",
    "import math\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import Augmentor\n",
    "import random\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "define the object directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_dir = \"objects\"\n",
    "\n",
    "# names of the folders in objects/\n",
    "categories = ['one_way_sign_left', 'one_way_sign_right', 'road_closed_sign', 'stop_sign', 'traffic_drum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth edges on template images\n",
    "# def smooth_borders(im):\n",
    "#     h, w = im.shape[:2]\n",
    "#     amt = 3\n",
    "#     top_bot = np.zeros((3, w, 4))\n",
    "#     top_bot[:] = (0, 0, 0, 0)\n",
    "#     left_right = np.zeros((h+2*amt, 3, 4))\n",
    "#     left_right[:] = (0, 0, 0, 0)\n",
    "\n",
    "#     im = np.concatenate((top_bot, im, top_bot), axis=0)\n",
    "#     im = np.concatenate((left_right, im, left_right), axis=1)\n",
    "\n",
    "#     b, g, r, a = cv2.split(im)\n",
    "#     a = cv2.GaussianBlur(a, (5,5), 5)\n",
    "#     smoothened = cv2.merge((b, g, r, a))\n",
    "\n",
    "#     return smoothened\n",
    "\n",
    "# for cat in categories:\n",
    "#     if not os.path.isdir(os.path.join(\"smooth\", cat)):\n",
    "#         os.mkdir(os.path.join(\"smooth\", cat))\n",
    "#     cat_path = os.path.join(object_dir, cat)\n",
    "#     objs = os.listdir(cat_path)\n",
    "#     for i, obj in enumerate(objs):\n",
    "#         obj_path = os.path.join(cat_path, obj)\n",
    "#         im = cv2.imread(obj_path, cv2.IMREAD_UNCHANGED)\n",
    "#         smooth = smooth_borders(im)\n",
    "#         cv2.imwrite(os.path.join(\"smooth\", cat, \"%s-%d.png\" % (cat, i)), smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "Next, we will perform a random perspective transform as well as motion blur on each image and generate 50 samples per template image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ɴᴏᴡ ᴘʟᴀʏɪɴɢ: one_way_sign_left \n",
      "───────────────⚪─────────────────── \n",
      "◄◄⠀▐▐ ⠀►►⠀⠀ 1:17 / 3:48 ⠀ ───○ 🔊⠀ ᴴᴰ ⚙ ❐ ⊏⊐\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef3be2998974c50953c8a255a0b5cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ɴᴏᴡ ᴘʟᴀʏɪɴɢ: one_way_sign_right \n",
      "───────────────⚪─────────────────── \n",
      "◄◄⠀▐▐ ⠀►►⠀⠀ 1:17 / 3:48 ⠀ ───○ 🔊⠀ ᴴᴰ ⚙ ❐ ⊏⊐\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19df06a0448c454b83413984c2da9332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ɴᴏᴡ ᴘʟᴀʏɪɴɢ: road_closed_sign \n",
      "───────────────⚪─────────────────── \n",
      "◄◄⠀▐▐ ⠀►►⠀⠀ 1:17 / 3:48 ⠀ ───○ 🔊⠀ ᴴᴰ ⚙ ❐ ⊏⊐\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93529e2d4b2c4daeb8584f365ef6ef1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=22), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ɴᴏᴡ ᴘʟᴀʏɪɴɢ: stop_sign \n",
      "───────────────⚪─────────────────── \n",
      "◄◄⠀▐▐ ⠀►►⠀⠀ 1:17 / 3:48 ⠀ ───○ 🔊⠀ ᴴᴰ ⚙ ❐ ⊏⊐\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd38e53fd904b95bdefeb5a735e9307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ɴᴏᴡ ᴘʟᴀʏɪɴɢ: traffic_drum \n",
      "───────────────⚪─────────────────── \n",
      "◄◄⠀▐▐ ⠀►►⠀⠀ 1:17 / 3:48 ⠀ ───○ 🔊⠀ ᴴᴰ ⚙ ❐ ⊏⊐\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e448f119de7d48cebee9e13b248fa78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Iterate through object classes\n",
    "if not os.path.isdir(\"temp\"):\n",
    "    os.mkdir(\"temp\")\n",
    "for cat in categories:\n",
    "    now_playing(cat)\n",
    "    if not os.path.isdir(os.path.join(\"temp\", cat)):\n",
    "        os.mkdir(os.path.join(\"temp\", cat))\n",
    "    # Iterate through images in classes\n",
    "    curr_dir = os.path.join(object_dir, cat)\n",
    "    cat_objs = os.listdir(curr_dir)\n",
    "    im_idx=1\n",
    "    for obj in tqdm(cat_objs):\n",
    "        obj_path = os.path.join(curr_dir, obj)\n",
    "        # Generate 50 samples from each object\n",
    "        for _ in range(50):\n",
    "            # Read image\n",
    "            im = cv2.imread(obj_path, cv2.IMREAD_UNCHANGED)\n",
    "            \n",
    "            # Perspective transform\n",
    "            if random.random() < 0.8:\n",
    "                im = perspective_transform(im)\n",
    "            \n",
    "            # Motion blur\n",
    "            if random.random() < 0.8:\n",
    "                im = motion_blur(im, size=random.randint(3, 15))\n",
    "            aug_path = \"temp/%s/%s-%d.png\" % (cat, cat, im_idx)\n",
    "            cv2.imwrite(aug_path, im)\n",
    "            im_idx += 1\n",
    "print(\"done!\")\n",
    "#             # JPEG Compression (to generate artifacts)\n",
    "#             im = compress_jpeg(im, min_quality=i*5, max_quality=i*5+5)\n",
    "\n",
    "            # Salt and pepper noise. Some papers claim it helps, some claim it hurts. who really knows?\n",
    "#             if(random.random() < 0.3):\n",
    "#                 im = noisy(im, \"s&p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Executing Pipeline:   0%|          | 0/2000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ɴᴏᴡ ᴘʟᴀʏɪɴɢ: one_way_sign_left \n",
      "───────────────⚪─────────────────── \n",
      "◄◄⠀▐▐ ⠀►►⠀⠀ 1:17 / 3:48 ⠀ ───○ 🔊⠀ ᴴᴰ ⚙ ❐ ⊏⊐\n",
      "Initialised with 1300 image(s) found.\n",
      "Output directory set to temp/one_way_sign_left/../../output/one_way_sign_left."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=616x256 at 0x7F01643910B8>: 100%|██████████| 2000/2000 [00:13<00:00, 153.45 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/2000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ɴᴏᴡ ᴘʟᴀʏɪɴɢ: one_way_sign_right \n",
      "───────────────⚪─────────────────── \n",
      "◄◄⠀▐▐ ⠀►►⠀⠀ 1:17 / 3:48 ⠀ ───○ 🔊⠀ ᴴᴰ ⚙ ❐ ⊏⊐\n",
      "Initialised with 1250 image(s) found.\n",
      "Output directory set to temp/one_way_sign_right/../../output/one_way_sign_right."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=383x150 at 0x7F0164502D30>: 100%|██████████| 2000/2000 [00:11<00:00, 181.60 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/2000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ɴᴏᴡ ᴘʟᴀʏɪɴɢ: road_closed_sign \n",
      "───────────────⚪─────────────────── \n",
      "◄◄⠀▐▐ ⠀►►⠀⠀ 1:17 / 3:48 ⠀ ───○ 🔊⠀ ᴴᴰ ⚙ ❐ ⊏⊐\n",
      "Initialised with 1100 image(s) found.\n",
      "Output directory set to temp/road_closed_sign/../../output/road_closed_sign."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=610x492 at 0x7F0164671E48>: 100%|██████████| 2000/2000 [00:14<00:00, 135.38 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/2000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ɴᴏᴡ ᴘʟᴀʏɪɴɢ: stop_sign \n",
      "───────────────⚪─────────────────── \n",
      "◄◄⠀▐▐ ⠀►►⠀⠀ 1:17 / 3:48 ⠀ ───○ 🔊⠀ ᴴᴰ ⚙ ❐ ⊏⊐\n",
      "Initialised with 1050 image(s) found.\n",
      "Output directory set to temp/stop_sign/../../output/stop_sign."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=632x623 at 0x7F0164666BA8>: 100%|██████████| 2000/2000 [00:17<00:00, 112.93 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/2000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ɴᴏᴡ ᴘʟᴀʏɪɴɢ: traffic_drum \n",
      "───────────────⚪─────────────────── \n",
      "◄◄⠀▐▐ ⠀►►⠀⠀ 1:17 / 3:48 ⠀ ───○ 🔊⠀ ᴴᴰ ⚙ ❐ ⊏⊐\n",
      "Initialised with 950 image(s) found.\n",
      "Output directory set to temp/traffic_drum/../../output/traffic_drum."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=257x416 at 0x7F016453B630>: 100%|██████████| 2000/2000 [00:13<00:00, 148.15 Samples/s] \n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"output\"):\n",
    "    os.mkdir(\"output\")\n",
    "for cat in categories:\n",
    "    now_playing(cat)\n",
    "    p = Augmentor.Pipeline(\"temp/\"+cat, output_directory=\"../../output/\"+cat)\n",
    "\n",
    "    # Slightly distort picture. It should add a little variance to the objects\n",
    "    p.random_distortion(probability=0.5, grid_width=4, grid_height=4, magnitude=1)\n",
    "\n",
    "    # Change brightness, color, contrast\n",
    "    p.random_brightness(probability=0.8, min_factor=0.6, max_factor=1)\n",
    "    p.random_color(     probability=0.8, min_factor=0.6, max_factor=1)\n",
    "    p.random_contrast(  probability=0.8, min_factor=0.5, max_factor=1)\n",
    "\n",
    "    # Replace random section with noise\n",
    "    p.random_erasing(probability=0.05, rectangle_area=0.65)\n",
    "    p.random_erasing(probability=0.1,  rectangle_area=0.55)\n",
    "    p.random_erasing(probability=0.3,  rectangle_area=0.35)\n",
    "    p.random_erasing(probability=0.3,  rectangle_area=0.25)\n",
    "    p.random_erasing(probability=0.3,  rectangle_area=0.15)\n",
    "\n",
    "    # 2D rotation\n",
    "    p.rotate_without_crop(probability=0.9, max_left_rotation=5, max_right_rotation=5, expand=True)\n",
    "    p.rotate_without_crop(probability=0.2, max_left_rotation=5, max_right_rotation=5, expand=True)\n",
    "\n",
    "    # Create 2000 new thumbnails for every class\n",
    "    p.sample(2000)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we paste the augmented objects onto background images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths of all backgrounds\n",
    "BG_PATH = os.path.join(\"backgrounds\", \"resize\")\n",
    "background_paths = [os.path.join(BG_PATH, bg_path) for bg_path in os.listdir(BG_PATH)]\n",
    "random.shuffle(background_paths)\n",
    "\n",
    "cat_paths = [os.path.join(\"output\", cat) for cat in categories]\n",
    "\n",
    "# Get paths of all generated objects\n",
    "obj_paths = []\n",
    "for cat in categories:\n",
    "    cat_path = os.path.join(\"output\", cat)\n",
    "    for obj_path in os.listdir(cat_path):\n",
    "        obj_paths.append({\n",
    "            \"category\": cat,\n",
    "            \"path\": os.path.join(cat_path, obj_path)\n",
    "        })\n",
    "\n",
    "# Shuffle object paths\n",
    "random.shuffle(obj_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18686  images left\n",
      "18186  images left\n",
      "17686  images left\n",
      "17186  images left\n",
      "16686  images left\n",
      "16186  images left\n",
      "15686  images left\n",
      "15186  images left\n",
      "14686  images left\n",
      "14186  images left\n",
      "13686  images left\n",
      "13186  images left\n",
      "12686  images left\n",
      "12186  images left\n",
      "11686  images left\n",
      "11186  images left\n",
      "10686  images left\n",
      "10186  images left\n",
      "9686  images left\n",
      "9186  images left\n",
      "8686  images left\n",
      "Copying over the remaining 8685 images...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"generated\"):\n",
    "    os.mkdir(\"generated\")\n",
    "curr_obj_idx = 0\n",
    "\n",
    "for bg_idx, bg_path in enumerate(background_paths):\n",
    "    if bg_idx % 500 == 0:\n",
    "        print(len(background_paths) - bg_idx, \" images left\")\n",
    "        \n",
    "    # Check if we've gone through all the objects\n",
    "    if bg_idx > 10000:\n",
    "        remaining_bgs = background_paths[bg_idx:]\n",
    "        print(\"Copying over the remaining\", len(remaining_bgs), \"images...\")\n",
    "        for rem_idx, rem_bg_path in enumerate(remaining_bgs):\n",
    "            new_bg_path = \"generated/rem-%d.jpg\" % rem_idx\n",
    "            bbox_path = \"generated/rem-%d.txt\" % rem_idx\n",
    "            \n",
    "            # Copy image to generated folder\n",
    "            copyfile(rem_bg_path, new_bg_path)\n",
    "            \n",
    "            # Create empty annotation file\n",
    "            open(bbox_path, 'w').close()\n",
    "        break\n",
    "        \n",
    "    background = cv2.imread(bg_path)\n",
    "    bg_h, bg_w = background.shape[:2]\n",
    "    \n",
    "    # Generate new path names\n",
    "    new_bg_path = \"generated/img-%d.jpg\" % bg_idx\n",
    "    bbox_path = \"generated/img-%d.txt\" % bg_idx\n",
    "    \n",
    "    # Open bounding box file\n",
    "    bbox_file = open(bbox_path, 'w')\n",
    "    \n",
    "    # Place between 1 and 5 objects on each image\n",
    "    num_objs = random.randint(1, 5)\n",
    "    ignore_bboxes = []\n",
    "    for _ in range(num_objs):\n",
    "        # If we've gone through all our objects, shuffle and go again\n",
    "        if curr_obj_idx >= len(obj_paths):\n",
    "            random.shuffle(obj_paths)\n",
    "            curr_obj_idx = 0\n",
    "        obj_cat = obj_paths[curr_obj_idx][\"category\"]\n",
    "        obj_path = obj_paths[curr_obj_idx][\"path\"]\n",
    "        \n",
    "        obj = cv2.imread(obj_path, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        background, bbox = paste_random(background, obj, ignore_bboxes)\n",
    "        ignore_bboxes.append(bbox)\n",
    "        \n",
    "        x1, y1 = bbox[0]\n",
    "        x2, y2 = bbox[1]\n",
    "        \n",
    "        bbox_file.write(\"%d %d %d %d %d %d %s\\n\" % (x1, y1, x2, y2, bg_w, bg_h, obj_cat))\n",
    "        curr_obj_idx += 1\n",
    "    bbox_file.close()\n",
    "    cv2.imwrite(new_bg_path, background)\n",
    "print(\"done!\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
